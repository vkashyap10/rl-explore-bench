# RL-Explore-Bench

A light-weight playground for **efficient exploration algorithms** in reinforcement learning, centred on an implementation of **VAPOR** (Variational Approximation of Posterior Optimality) from *â€œProbabilistic Inference in Reinforcement Learning Done Rightâ€* and a reference baseline of **Posterior Sampling RL (PSRL)**. This repository provides an unofficial implementation of the VAPOR algorithm.

| VAPOR in action | Average episodic return | Posterior reward uncertainty |
| :--: | :--: | :--: |
| ![Deep-Sea Exploration](grid_world/assets/env_reward.gif) | ![Return](grid_world/assets/mean_reward_30_horizon.png) | ![Uncertainty](grid_world/assets/reward_uncertainty_30_horizon.png) |

---

## ðŸ“‚  Repository layout

```
rl-explore-bench/
â”‚
â”œâ”€ algorithms/          # VAPOR & PSRL implementations
â”‚   â”œâ”€ vapor.py
â”‚   â””â”€ psrl.py
â”‚
â”œâ”€ assets/              # GIF + figures used in the README
â”œâ”€ configs/             # Parameters for running experiments
â”‚
â”œâ”€ envs/                # Deep-Sea environment
â”‚   â”œâ”€ grid_utils.py
â”‚   â””â”€ wrappers.py
â”‚
â”œâ”€ planning/            # Value-iteration & VAPOR solver
â”œâ”€ sampling/            # Posterior samplers / distributions
â”œâ”€ examples/            # Demo
â”‚   â””â”€ deep_sea_demo.py
â””â”€ utils                # utilties for visualisation
```

---

## âš¡  Installation

> **Prerequisites** â€“ Linux/macOS, Python â‰¥ 3.9.

```bash
# Clone the repository
git clone https://github.com/vkashyap10/rl-explore-bench.git
cd rl-explore-bench

# Create a conda environment with Python â‰¥ 3.11
conda create -n rl-explore-bench python=3.11 -y
conda activate rl-explore-bench

# Install dependencies
pip install -U pip wheel
pip install -e .                   # installs cvxpy, numpy, matplotlib, tqdm, ruff â€¦

```

---

## ðŸš€  Quick start

Run the comparison between VAPOR and PSRL on the Deep-Sea environment (default: 30-time steps per episode, 100 episodes):

```bash
python grid_world/examples/deep_sea_demo.py

```

---

## ðŸ“– References

VAPOR
```bibtex
@misc{tarbouriech2023probabilisticinferencereinforcementlearning,
      title={Probabilistic Inference in Reinforcement Learning Done Right}, 
      author={Jean Tarbouriech and Tor Lattimore and Brendan O'Donoghue},
      year={2023},
      eprint={2311.13294},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2311.13294}, 
}
```
Posterior Sampling RL
```bibtex
@misc{osband2013moreefficientreinforcementlearning,
      title={(More) Efficient Reinforcement Learning via Posterior Sampling}, 
      author={Ian Osband and Daniel Russo and Benjamin Van Roy},
      year={2013},
      eprint={1306.0940},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1306.0940}, 
}
```
---
